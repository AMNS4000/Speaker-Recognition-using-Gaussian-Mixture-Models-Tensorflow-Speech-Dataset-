{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6922980,"sourceType":"datasetVersion","datasetId":3975219},{"sourceId":8940361,"sourceType":"datasetVersion","datasetId":5379421}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#IMPORTING THE LIBRARIES.\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport librosa","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parent_directory=\"/kaggle/input/speechdataset/SpeechCommand-20231108T141130Z-001/SpeechCommand\"\nfolder_list=os.listdir(parent_directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mapping = {'right': 0, 'eight': 1, 'cat': 2, 'tree': 3, 'bed': 4, 'happy': 5, 'go': 6, 'dog': 7, 'no': 8, 'wow': 9,\n                 'nine': 10, 'left': 11, 'stop': 12, 'three': 13, 'sheila': 14, 'one': 15, 'bird': 16, 'zero': 17,\n                 'seven': 18, 'up': 19, 'marvin': 20, 'two': 21, 'house': 22, 'down': 23, 'six': 24, 'yes': 25,\n                 'on': 26, 'five': 27, 'off': 28, 'four': 29}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Audio file for MFCC extraction\naudio_data, sample_rate = librosa.load(\"/kaggle/input/speechdataset/SpeechCommand-20231108T141130Z-001/SpeechCommand/bed/00176480_nohash_0.wav\")\nframe_length = int(sample_rate * 0.025) \nhop_length = int(sample_rate * 0.010)\nmfccs = librosa.feature.mfcc(y = audio_data,sr = sample_rate, n_mfcc = 13, n_fft = frame_length, hop_length = hop_length)\ndeltas = librosa.feature.delta(mfccs)\ndeltas_deltas = librosa.feature.delta(mfccs,order=2)\nprint(mfccs.shape)\nprint(deltas.shape)\nprint(deltas_deltas.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mfcc_list = []\ndelta_mfcc_list = []\ndelta_delta_mfcc_list = []\ncombined_train_data_list = []\nclass_label_list = []\n\n# LIST FOR EACH CLASS\nmfccs_list = []\ndelta_list = []\ndelta_delta_list = []\nlabels = []\n\n# Iterate through each class\nfor class_name, class_label in class_mapping.items():\n    class_directory = os.path.join(parent_directory, class_name)\n    mfccs_list = []\n    delta_list = []\n    delta_delta_list = []\n    combined_list = []\n    labels = []\n\n    for filename in os.listdir(class_directory):\n        if filename.endswith(\".wav\"):  \n            file_path = os.path.join(class_directory, filename)\n            audio_data, sample_rate = librosa.load(file_path, sr=22050)  \n            \n            frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n            hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n            frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n            n_mfcc = 13 \n            mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n            delta = librosa.feature.delta(mfccs)\n            delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n            mfccs_list.append(mfccs.T)\n            delta_list.append(delta.T)\n            delta_delta_list.append(delta_delta.T)\n            labels.append(class_label)\n            \n    mfcc_features = np.concatenate(mfccs_list)\n    delta_features = np.concatenate(delta_list)\n    delta_delta_features = np.concatenate(delta_delta_list)\n    combined_features=np.hstack((mfcc_features,delta_features,delta_delta_features))\n    print(f\"Shape of mfcc_features {mfcc_features.shape}\")\n    \n    class_mfcc_list.append(mfcc_features)\n    delta_mfcc_list.append(delta_features)\n    delta_delta_mfcc_list.append(delta_delta_features)\n    combined_train_data_list.append(combined_features)\n    class_label_list.append(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\nclass_gmms = {}\n\nfor class_label, features in zip(class_label_list, combined_train_data_list):\n    gmm = GaussianMixture(n_components=1, covariance_type='full', random_state=42)\n    gmm.fit(features)\n    class_gmms[class_label[0]] = gmm\n    print(f\" Done Class {class_label[0]}\")","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_directory=\"/kaggle/input/speechdataset/SpeechCommandTest-20231108T114713Z-001/SpeechCommandTest\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-gmm/test.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_file_columns=data['AUDIO_FILE']\ntest_data_list=audio_file_columns.to_list()\nlen(test_data_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mfcc_list = []\ntest_delta_list = []\ntest_delta_delta_list = []\ncombined_test_data_list=[]\nfor audio in test_data_list:\n    file_path=os.path.join(test_data_directory,audio)\n    audio_data, sample_rate = librosa.load(file_path, sr=None)\n    \n    frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n    hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n    n_mfcc = 13\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    combined_features=np.hstack((mfccs.T,delta.T,delta_delta.T))\n    \n    test_mfcc_list.append(mfccs.T)\n    test_delta_list.append(delta.T)\n    test_delta_delta_list.append(delta_delta.T)\n    combined_test_data_list.append(combined_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_test_data_list[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels_list = []\n\nfor features in combined_test_data_list:\n    likelihoods = {}\n    for class_label, gmm_model in class_gmms.items():\n        likelihood= gmm_model.score(features)\n        \n        likelihoods[class_label] = likelihood\n    predicted_label = max(likelihoods, key=likelihoods.get)\n    predicted_labels_list.append(predicted_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/test-gmm/test.csv\")\ndata['TARGET']=predicted_labels_list\ndata.drop(columns=['AUDIO_FILE'], inplace=True)\n# Save DataFrame to a CSV file\ndata.to_csv('predicted_labels.csv', index=False)  # Change 'predicted_labels.csv' to your desired file name\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}